# Phase 1 Materials: Comprehensive Plan
## Week 3-6 Workshop Templates (16개) + Example Materials (24개)

**Created**: 2025-10-09
**Purpose**: Complete blueprint for Week 3-6 Figma workshop materials following Week 1 model

---

## Overview

### Design Principles
1. **Consistency with Week 1**: Follow established Figma layout, 3-stage workshop process
2. **AI-Enhanced**: Each week integrates AI prompt recipes into hands-on activities
3. **Real Psychology Examples**: All examples from actual psychology/neuroscience research
4. **Progressive Difficulty**: Week 3 (Gap discovery) → Week 4 (Bulletproofing) → Week 5 (AI Reviewer) → Week 6 (Proposal)
5. **Cumulative Recipe Library**: Best practices accumulate across weeks

### Deliverables Summary

**Per Week**:
- **4 Workshop Templates**: Canvas layouts for Figma (3840×2160px)
- **6 Example Materials**: Concrete practice materials with before/after versions

**Total**:
- **16 Templates** (4 weeks × 4 templates)
- **24 Examples** (4 weeks × 6 examples)

---

## WEEK 3: Research Gap Discovery & Validation

### Learning Objectives
- Distinguish Incremental vs Conceptual/Mechanistic/Translational gaps
- Master 3-stage gap validation workflow
- Prevent false gaps through systematic validation
- Use AI to discover cross-disciplinary connections

### Workshop Templates (4)

**Template 3.1**: Gap Discovery Canvas (20 min individual experimentation)
**Template 3.2**: 3-Stage Validation Worksheet (25 min systematic validation)
**Template 3.3**: Peer Review Rubric for Gap Discovery (20 min structured feedback)
**Template 3.4**: Recipe Library - Week 3 Cumulative (growing collection)

### Example Materials (6)

**Example 3.1**: Incremental Gap - Bad Example (Psychology research)
- Shows what NOT to do
- AI-assisted classification as incremental
- Transformation guide to conceptual gap

**Example 3.2**: Conceptual Gap - Good Example (Cognitive Neuroscience)
- Nature Neuroscience-level gap
- Complete 3-stage validation
- Shows all criteria (Surprise, Consequential, Tractable)

**Example 3.3**: Mechanistic Gap - Good Example (Neuroscience)
- Focuses on HOW questions
- Causal mechanism identification
- Intervention-based testing

**Example 3.4**: 3-Stage Validation Success Story
- Complete validation workflow that PASSES
- Before/after gap statement comparison
- Shows transformation from initial to final version

**Example 3.5**: 3-Stage Validation Failure (False Gap Detection)
- Validation workflow that FAILS at Stage 1
- Shows how to rescue false gaps (refine or pivot)
- Prevents wasted research effort

**Example 3.6**: Model Peer Review for Gap Discovery
- Exemplary peer review using 4-dimension rubric
- Balanced strengths + concerns + actionable suggestions
- Shows professional feedback style

---

## WEEK 4: Methods/Results Bulletproofing

### Learning Objectives
- Identify Top 10 rejection reasons for Methods/Results
- Master 6-item reproducibility checklist
- Validate statistical rigor and control adequacy
- Prevent overclaiming through adversarial review
- Use AI for bulletproofing audit

### Workshop Templates (4)

**Template 4.1**: Bulletproofing Audit Canvas (25 min)
- Canvas Structure: Left panel (Top 10 rejection reasons + 6-item checklist), Right panel (Student audit zones)
- Key Features: Before/After comparison, Red flag detection, Fix prioritization
- Interaction: Students paste Methods/Results → AI audit → Identify weaknesses → Prioritize fixes

**Template 4.2**: Red Team/Blue Team Game Board (20 min statistical rigor)
- Canvas Structure: Left panel (Statistical rigor criteria), Right panel (Attack/Defense zones)
- Game Mechanics: Red Team attacks statistics → Blue Team defends → Instructor adjudicates
- Key Features: Attack cards (common statistical flaws), Defense cards (proper justifications), Score tracking

**Template 4.3**: Reproducibility Checklist Worksheet (embedded in 4.1)
- 6 Critical Elements: Sample details, Materials/Measures, Procedure specificity, Data availability, Code sharing, Pre-registration
- Scoring: Each element 0-5 points (0=missing, 5=exemplary)
- Pass threshold: All elements ≥ 3/5

**Template 4.4**: Peer Review Rubric for Bulletproofing (20 min)
- 4 Dimensions: Reproducibility (40%), Statistical Rigor (30%), Control Adequacy (20%), Claim Appropriateness (10%)
- Structured feedback: Strengths + Weaknesses + Top 3 Priority Fixes
- Integration with Templates 4.1-4.2 results

### Example Materials (6)

**Example 4.1**: Bad Methods Section #1 (Missing Reproducibility)
- Real/realistic psychology Methods section with critical gaps
- Missing: Sample recruitment details, measure reliability, exact procedure steps
- AI audit reveals problems
- Model revision with all 6 checklist items

**Example 4.2**: Good Methods Section #1 (All 6 Checklist Items Present)
- Nature Human Behaviour-level Methods
- Annotated to show where each checklist item appears
- Comparison table: Bad vs Good for each item

**Example 4.3**: Bad Results Section #1 (Overclaiming + Weak Statistics)
- Overclaims: "proves," "demonstrates causality" (from correlational data)
- Weak statistics: No effect sizes, no corrections for multiple comparisons, cherry-picked analyses
- AI Red Team attack identifies all flaws

**Example 4.4**: Good Results Section #1 (Appropriate Claims + Rigorous Stats)
- Appropriate language: "suggests," "consistent with," "associated with"
- Rigorous stats: Effect sizes (Cohen's d), corrections (FDR), sensitivity analyses
- Annotated to show best practices

**Example 4.5**: Red Team Attack + Blue Team Defense Case Study
- Complete game transcript: Attack → Defense → Adjudication
- Shows 5 rounds of attack/defense
- Example attacks: "No power analysis," "Multiple comparisons uncorrected," "Confounds not addressed"
- Example defenses (good and bad)

**Example 4.6**: Model Peer Review for Bulletproofing
- Complete review using 4-dimension rubric
- Identifies specific weaknesses (e.g., "Line 47: Sample size not justified")
- Provides Top 3 Priority Fixes with concrete steps
- Shows how to give constructive criticism

---

## WEEK 5: AI Reviewer Simulation & Discussion Section

### Learning Objectives
- Use 3-Pass Revision strategy (Macro → Meso → Micro)
- Simulate Nature/Science reviewer feedback with AI
- Identify and fix structural problems (Macro pass)
- Refine section-level logic (Meso pass)
- Polish sentence-level clarity (Micro pass)
- Master Discussion section best practices

### Workshop Templates (4)

**Template 5.1**: AI Diagnostic Canvas (25 min)
- Canvas Structure: Left panel (3-Pass strategy overview + diagnostic criteria), Right panel (Student diagnostic zones)
- 3 Passes:
  - Macro (structure): Does argument flow logically? Are sections in right order?
  - Meso (sections): Does each paragraph have clear topic sentence? Do paragraphs connect?
  - Micro (sentences): Are sentences clear? Any jargon? Passive voice?
- AI Recipes: #1-5 for diagnostics
- Output: Prioritized problem list (fix Macro first, then Meso, then Micro)

**Template 5.2**: 3-Pass Revision Worksheet (25 min)
- Canvas Structure: 3 vertical sections (Macro pass → Meso pass → Micro pass)
- Each section: Before text → AI feedback → After text
- Tracks changes: What changed? Why? How did AI help?

**Template 5.3**: AI Reviewer Simulation Board (15 min)
- Canvas Structure: Left panel (Reviewer personas: Reviewer 1=Methodology expert, Reviewer 2=Theory expert, Reviewer 3=Statistics expert), Right panel (3 parallel review zones)
- Key Feature: Same Discussion section → 3 different AI reviewers → Synthesize criticisms
- AI Recipes: #10, #11, #12 for reviewer simulation
- Output: Consolidated revision plan (what satisfies all 3 reviewers?)

**Template 5.4**: Peer Review Rubric for Discussion Sections (15 min)
- 4 Dimensions: Interpretation Quality (40%), Limitation Acknowledgment (30%), Implication Clarity (20%), Structure (10%)
- Focus: "Does this Discussion section feel like Nature/Science?" (not just "is it okay?")

### Example Materials (6)

**Example 5.1**: Discussion Section - Before AI Diagnostic (with problems)
- Real Discussion section with structural, sectional, and sentence-level problems
- Problems annotated: [Macro: no clear narrative arc], [Meso: paragraphs jump topics], [Micro: jargon-heavy sentences]

**Example 5.2**: Discussion Section - After AI Diagnostic (problems identified)
- Same section with AI feedback overlaid
- Color-coded: Red (Macro), Orange (Meso), Yellow (Micro)
- Shows diagnostic output from AI Recipe #3

**Example 5.3**: 3-Pass Revision Case Study - Macro Pass (structure fixes)
- Before: 5 paragraphs in poor order (Limitations → Main finding → Implications → Mechanism → Future)
- AI feedback: "Reorganize as: Main finding → Mechanism → Broader implications → Limitations → Future"
- After: Revised structure with transition sentences added

**Example 5.4**: 3-Pass Revision Case Study - Meso Pass (section-level fixes)
- Before: Paragraph with weak topic sentence + disconnected ideas
- AI feedback: "Topic sentence vague ('Results are interesting'). No clear connection to previous paragraph."
- After: Strong topic sentence ("Our findings suggest X") + explicit connection ("Building on the mechanism above...")

**Example 5.5**: 3-Pass Revision Case Study - Micro Pass (sentence-level fixes)
- Before: 10 problematic sentences (passive voice, jargon, wordiness)
- AI feedback for each sentence
- After: 10 revised sentences (active voice, plain language, concise)
- Comparison table: Before vs After with specific changes highlighted

**Example 5.6**: AI Reviewer Feedback - 3 Reviewers on Same Section
- Discussion section submitted to 3 AI reviewers
- Reviewer 1 (Methodology): "Sample size limits generalizability. Address in Limitations."
- Reviewer 2 (Theory): "Theoretical implications unclear. How does this change our understanding of X?"
- Reviewer 3 (Statistics): "Effect sizes not discussed. Are these practically significant?"
- Student response: Revised Discussion addressing all 3 concerns

---

## WEEK 6: Research Proposal Writing

### Learning Objectives
- Master 5 Hook patterns for opening (Problem/Question/Paradox/Narrative/Bold Claim)
- Structure proposals using 3-Stage framework (Problem → Solution → Impact)
- Build Impact Pyramid (Immediate → Medium-term → Long-term)
- Use AI to generate multiple hook variations
- Simulate funder/reviewer feedback on proposals

### Workshop Templates (4)

**Template 6.1**: Hook Generation Canvas (20 min)
- Canvas Structure: Left panel (5 Hook patterns with examples), Right panel (Student hook experiment zones)
- 5 Patterns:
  1. Problem-First: "Current methods fail to..."
  2. Question-First: "Can we predict X from Y?"
  3. Paradox-First: "Despite X, we observe Y..."
  4. Narrative-First: "In 2020, a patient presented with..."
  5. Bold Claim-First: "We will demonstrate that..."
- Activity: Students generate 3 hooks (different patterns) for same proposal → Peer vote on best

**Template 6.2**: 3-Stage Structure Builder (30 min)
- Canvas Structure: 3 horizontal sections (Problem → Solution → Impact)
- Problem Section: Gap statement (from Week 3) + why it matters
- Solution Section: Specific aims, methods, innovation
- Impact Section: Impact Pyramid (Immediate/Medium/Long-term)
- Integration: Each section feeds into next (Problem motivates Solution; Solution enables Impact)

**Template 6.3**: Impact Pyramid Worksheet (embedded in 6.2)
- 3 Levels:
  - Immediate (1-2 years): Direct findings, method validation
  - Medium-term (3-5 years): Field applications, theory refinement
  - Long-term (10+ years): Societal impact, paradigm shift
- Scoring: Is each level plausible? Supported by proposal logic?

**Template 6.4**: AI Reviewer Simulation for Proposals (15 min)
- Canvas Structure: Left panel (Funder priorities: Innovation, Impact, Feasibility), Right panel (AI reviewer feedback zones)
- AI Personas: NSF Program Officer, NIH Study Section, Industry R&D Director
- Output: Critique + Revision suggestions

### Example Materials (6)

**Example 6.1**: Problem-First Hook Example (Psychology)
- Complete proposal opening using Problem-First hook
- Annotated: Hook (1 sentence) → Gap (2 sentences) → Impact preview (1 sentence)
- Why it works: Immediately establishes urgency

**Example 6.2**: Question-First Hook Example (Neuroscience)
- Complete proposal opening using Question-First hook
- Comparison: vs Problem-First approach for same topic
- When to use: Exploratory research, mechanism discovery

**Example 6.3**: Paradox-First Hook Example (Cognitive Science)
- Complete proposal opening using Paradox-First hook
- Structure: "Everyone assumes X, but data shows Y..." → "Why this paradox?" → "Our solution"
- When to use: Challenging established theories

**Example 6.4**: Complete 3-Stage Proposal Example
- Full 2-page proposal: Hook → Problem → Solution (3 Aims + Methods) → Impact Pyramid
- Annotated to show: Where each element appears, transitions between sections
- Success metrics: Why this would be competitive for NIH R01 or NSF CAREER

**Example 6.5**: Impact Pyramid Case Study
- Proposal with weak Impact section (only Immediate impacts listed)
- AI expansion (Recipe #20): Generates Medium and Long-term impacts
- Before/After comparison: 3 sentences → 9 sentences (3 per level)
- Evaluation: Which impacts are plausible vs speculative?

**Example 6.6**: AI Reviewer Feedback on Complete Proposal
- 2-page proposal submitted to 3 AI reviewers (NSF, NIH, Industry)
- NSF: "Innovation strong, but broader impacts need specific metrics"
- NIH: "Significance excellent, but Approach lacks preliminary data"
- Industry: "Feasibility good, but timeline too long for commercial relevance"
- Student revision: Addresses all 3 reviewers' concerns

---

## Implementation Timeline

### Creation Sequence (Recommended)

**Phase 1A: Week 3 Materials** (Target: 3 days)
- Day 1: Templates 3.1-3.2 (Gap Discovery + Validation)
- Day 2: Templates 3.3-3.4 (Peer Review + Recipe Library)
- Day 3: Examples 3.1-3.6 (all 6 examples)

**Phase 1B: Week 4 Materials** (Target: 3 days)
- Day 1: Templates 4.1-4.2 (Bulletproofing + Red Team/Blue Team)
- Day 2: Template 4.3-4.4 (Checklist + Peer Review)
- Day 3: Examples 4.1-4.6 (all 6 examples)

**Phase 1C: Week 5 Materials** (Target: 3 days)
- Day 1: Templates 5.1-5.2 (AI Diagnostic + 3-Pass Revision)
- Day 2: Templates 5.3-5.4 (AI Reviewer + Peer Review)
- Day 3: Examples 5.1-5.6 (all 6 examples)

**Phase 1D: Week 6 Materials** (Target: 3 days)
- Day 1: Templates 6.1-6.2 (Hook Generation + 3-Stage Structure)
- Day 2: Templates 6.3-6.4 (Impact Pyramid + AI Reviewer)
- Day 3: Examples 6.1-6.6 (all 6 examples)

**Total Estimated Time**: 12 days (3 days per week × 4 weeks)

---

## Quality Assurance Checklist

### For Each Template
- [ ] Consistent with Week 1 Figma layout (3840×2160px)
- [ ] Left panel (reference) + Right panel (workspace) structure
- [ ] 3-stage workshop process integrated
- [ ] AI prompt recipes explicitly referenced
- [ ] Recipe library accumulation mechanism
- [ ] Clear interaction instructions
- [ ] Student work zones sized appropriately (700×400px typical)

### For Each Example
- [ ] Real or highly realistic psychology/neuroscience scenario
- [ ] Before/After comparison (where applicable)
- [ ] AI-assisted analysis demonstrated
- [ ] Transformation guide included (how to improve)
- [ ] Practice exercise for students
- [ ] Self-check questions included
- [ ] Annotated to highlight key teaching points

### Cross-Week Integration
- [ ] Recipe library accumulates (Week 2 → 3 → 4 → 5 → 6)
- [ ] Difficulty progression (easier → harder across weeks)
- [ ] Examples reference previous week's concepts
- [ ] Templates reuse successful patterns from earlier weeks
- [ ] Peer review rubrics evolve (more sophisticated each week)

---

## File Structure

```
week3/
├── template_3.1_gap_discovery_canvas.md
├── template_3.2_3stage_validation_worksheet.md
├── template_3.3_peer_review_rubric_gap.md
├── template_3.4_recipe_library_week3.md
├── example_3.1_incremental_gap_bad.md
├── example_3.2_conceptual_gap_good.md
├── example_3.3_mechanistic_gap_good.md
├── example_3.4_validation_success.md
├── example_3.5_validation_failure.md
└── example_3.6_peer_review_model.md

week4/
├── template_4.1_bulletproofing_audit.md
├── template_4.2_red_team_blue_team.md
├── template_4.3_reproducibility_checklist.md
├── template_4.4_peer_review_rubric_bulletproofing.md
├── example_4.1_bad_methods.md
├── example_4.2_good_methods.md
├── example_4.3_bad_results.md
├── example_4.4_good_results.md
├── example_4.5_red_team_blue_team_game.md
└── example_4.6_peer_review_model.md

week5/
├── template_5.1_ai_diagnostic.md
├── template_5.2_3pass_revision_worksheet.md
├── template_5.3_ai_reviewer_simulation.md
├── template_5.4_peer_review_rubric_discussion.md
├── example_5.1_discussion_before_diagnostic.md
├── example_5.2_discussion_after_diagnostic.md
├── example_5.3_macro_pass_case_study.md
├── example_5.4_meso_pass_case_study.md
├── example_5.5_micro_pass_case_study.md
└── example_5.6_ai_reviewer_feedback.md

week6/
├── template_6.1_hook_generation.md
├── template_6.2_3stage_structure_builder.md
├── template_6.3_impact_pyramid.md
├── template_6.4_ai_reviewer_proposals.md
├── example_6.1_problem_first_hook.md
├── example_6.2_question_first_hook.md
├── example_6.3_paradox_first_hook.md
├── example_6.4_complete_proposal.md
├── example_6.5_impact_pyramid_case_study.md
└── example_6.6_ai_reviewer_feedback_proposal.md
```

---

## Next Steps

1. **Review this plan** with course instructor for feedback
2. **Prioritize Week 3 materials** (most immediately needed)
3. **Create templates first** (defines structure for examples)
4. **Develop examples second** (fills in templates with concrete content)
5. **Test in pilot workshop** (Week 3 materials with small group)
6. **Iterate based on feedback** before creating Week 4-6

---

## Notes for AI Assistant (Future Reference)

- **Week 1 Pattern**: Refer to `week1/workshop_materials.md` and `week1/figma_workshop_guide.md` for structure model
- **Strategy Alignment**: Check `claudedocs/figma_workshop_weeks2-6.md` for each week's specific strategies
- **Lecture Integration**: Each template/example should align with corresponding `weekN/lecture_notes.md`
- **No Concept Explanations**: Week 2-6 assume students know AI concepts (from 윤경생's lectures); focus on APPLICATION
- **Real Examples**: Psychology/Neuroscience preferred; cite real papers where possible (Nature, Science, PNAS, JPSP)
- **Peer Learning Emphasis**: All templates should facilitate peer review/feedback (not just instructor-student)

**End of Comprehensive Plan**
