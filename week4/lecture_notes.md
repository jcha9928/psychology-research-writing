# 4ì£¼ì°¨ ê°•ì˜ë…¸íŠ¸: AI í™œìš©â…¢ â€“ Methods/Results Bulletproofing ì „ëµ

> **ì „ì œ**: ìœ¤ê²½ìƒ ë°•ì‚¬ë‹˜ ê°•ì˜ì—ì„œ Chain-of-Thought (CoT) í”„ë¡¬í”„íŒ…ì„ ì´ë¯¸ í•™ìŠµí–ˆë‹¤ëŠ” ì „ì œí•˜ì— ì§„í–‰í•©ë‹ˆë‹¤. ë³¸ ê°•ì˜ì—ì„œëŠ” CoT **ê¸°ë²•**ì´ ì•„ë‹Œ, "ì–´ë–»ê²Œ í•˜ë©´ íƒ‘í‹°ì–´ ì €ë„ ë¦¬ë·°ì–´ì˜ methodological/statistical ê³µê²©ì„ ë°©ì–´í•  ìˆ˜ ìˆëŠ” Methods/Resultsë¥¼ ì‘ì„±í•˜ëŠ”ê°€?"ì— ì§‘ì¤‘í•©ë‹ˆë‹¤.

## í•™ìŠµ ëª©í‘œ
- **íƒ‘í‹°ì–´ ì €ë„ì˜ Methods/Results ê±°ë¶€ ì‚¬ìœ ** íŒŒì•… ë° ì˜ˆë°©
- **Reproducibility, control, statistical rigor** ì²´í¬ë¦¬ìŠ¤íŠ¸ ì‹¤í–‰
- **Overclaiming ë°©ì§€ ë° transparent reporting** ì „ëµ ì ìš©
- AIë¥¼ í™œìš©í•œ self-critique ë° preemptive reviewer response
- **ê¶ê·¹ ëª©í‘œ: ë¦¬ë·°ì–´ì˜ methodological/statistical ê³µê²©ì„ ë°©ì–´í•  ìˆ˜ ìˆëŠ” Methods/Results ì‘ì„± ëŠ¥ë ¥ ê°œë°œ**

---

## ğŸ“š ìˆ˜ì—… ì „ ì¤€ë¹„ (ê³¼ì œ)

**í•„ìˆ˜ ê³¼ì œ**: Methods & Results ì„¹ì…˜ ì´ˆì•ˆ ì‘ì„±
- **Methods** (800-1000 words): Participants, Materials, Procedure, Analysis í¬í•¨
- **Results** (600-800 words): ì£¼ìš” ê²°ê³¼ + ìµœì†Œ 1ê°œ Figure/Table
- Week 3ì˜ gapì„ í•´ê²°í•˜ëŠ” ì—°êµ¬ ë°©ë²•ë¡  ì œì‹œ
- ì™„ë²½í•˜ì§€ ì•Šì•„ë„ ë¨ - ìˆ˜ì—…ì—ì„œ AIë¡œ bulletproofingí•  ì˜ˆì •

---

## ğŸ“ 90ë¶„ Workshop êµ¬ì¡°

**ê°•ì˜ 15-20ë¶„** + **Workshop/Discussion 70-75ë¶„**

í•™ìƒë“¤ì€ ìì‹ ì˜ Methods/Resultsë¥¼ ê°€ì§€ê³  ì™€ì„œ:
- AIë¡œ reproducibility audit (ì·¨ì•½ì  10ê°œ ì°¾ê¸°)
- Control strategy ê²€ì¦ (alternative explanation ë°°ì œ)
- Statistical rigor ì²´í¬ (power, assumptions, effect size)
- Overclaiming ë°©ì§€ (claim-evidence match)
- Preemptive reviewer response (ì˜ˆìƒ ì§ˆë¬¸ ëŒ€ì‘)
- ë™ë£Œ í”¼ë“œë°± ë° ê°œì„ 

---

## ğŸ“Š 90ë¶„ In-Class Workshop ì§„í–‰

### ì§§ì€ ê°•ì˜ (15-20ë¶„)

**í•µì‹¬ ê°œë… ë¦¬ë·°:**

## 1. íƒ‘í‹°ì–´ ì €ë„ì˜ Methods/Results ê±°ë¶€ ì‚¬ìœ 

### 1.1 Common Rejection Patterns

#### Methods ì„¹ì…˜ ê±°ë¶€ ì‚¬ìœ  (Top 5)

1. **Insufficient detail for reproduction**
   - "ë‹¤ë¥¸ ì—°êµ¬ìê°€ ì´ ì—°êµ¬ë¥¼ ì¬í˜„í•  ìˆ˜ ì—†ë‹¤"
   - ì˜ˆ: ìê·¹ ìƒì„± ê³¼ì • ë¶ˆëª…í™•, í†µê³„ íŒŒë¼ë¯¸í„° ëˆ„ë½

2. **Inadequate controls**
   - "ëŒ€ì•ˆ ì„¤ëª…ì„ ë°°ì œí•˜ì§€ ëª»í–ˆë‹¤"
   - ì˜ˆ: Confound ë³€ìˆ˜ í†µì œ ì•ˆ ë¨, negative control ì—†ìŒ

3. **Sample size/power issues**
   - "í†µê³„ì  ê²€ì •ë ¥ì´ ë¶€ì¡±í•˜ë‹¤"
   - ì˜ˆ: N ì •ë‹¹í™” ì—†ìŒ, multiple comparison ê³ ë ¤ ì•ˆ ë¨

4. **Inappropriate statistics**
   - "ë¶„ì„ ë°©ë²•ì´ ë°ì´í„° êµ¬ì¡°ì— ë§ì§€ ì•Šë‹¤"
   - ì˜ˆ: ê°€ì • ìœ„ë°°, ì˜ëª»ëœ ê²€ì • ì„ íƒ

5. **Validation gaps**
   - "ì¸¡ì • ë„êµ¬/ë°©ë²•ì˜ íƒ€ë‹¹ì„± ì…ì¦ ë¶€ì¡±"
   - ì˜ˆ: Manipulation check ì—†ìŒ, ì‹ ë¢°ë„/íƒ€ë‹¹ë„ ë³´ê³  ì•ˆ ë¨

#### Results ì„¹ì…˜ ê±°ë¶€ ì‚¬ìœ  (Top 5)

1. **Overclaiming**
   - "ë°ì´í„°ê°€ ë’·ë°›ì¹¨í•˜ì§€ ì•ŠëŠ” ì£¼ì¥"
   - ì˜ˆ: Correlationì„ causationìœ¼ë¡œ ì£¼ì¥

2. **Cherry-picking**
   - "ì¼ë¶€ ê²°ê³¼ë§Œ ì„ íƒì  ë³´ê³ "
   - ì˜ˆ: Hypothesisì— ë§ëŠ” ê²ƒë§Œ ë³´ê³ , ì•ˆ ë§ëŠ” ê²ƒ ìˆ¨ê¹€

3. **Statistical issues**
   - "ë‹¤ì¤‘ ë¹„êµ ë³´ì • ëˆ„ë½, p-hacking ì˜ì‹¬"
   - ì˜ˆ: 20ê°œ ë¹„êµ ì¤‘ 1ê°œë§Œ ìœ ì˜ â†’ ê·¸ê²ƒë§Œ ë³´ê³ 

4. **Unclear presentation**
   - "í•µì‹¬ ê²°ê³¼ê°€ ë¬´ì—‡ì¸ì§€ ë¶ˆëª…í™•"
   - ì˜ˆ: ì—„ì²­ë‚œ ì–‘ì˜ ê²°ê³¼ ë‚˜ì—´, ì¤‘ìš”ë„ êµ¬ë¶„ ì•ˆ ë¨

5. **Weak effect sizes**
   - "í†µê³„ì  ìœ ì˜ì„±ì€ ìˆì§€ë§Œ ì‹¤ì§ˆì  ì˜ë¯¸ ë¯¸ì•½"
   - ì˜ˆ: p < 0.001 but Cohen's d = 0.1

### 1.2 ì‹¤ìŠµ: Rejection Reason ì§„ë‹¨

**í™œë™:**
êµìˆ˜ê°€ ì œì‹œí•˜ëŠ” 3ê°œì˜ Methods/Results ì˜ˆì‹œë¥¼ ì½ê³ , ê°ê°ì˜ ê±°ë¶€ ì‚¬ìœ ë¥¼ 10ê°€ì§€ ì¹´í…Œê³ ë¦¬ì—ì„œ ì°¾ê¸°

**AI í”„ë¡¬í”„íŠ¸ ë ˆì‹œí”¼:**
```
"ë‹¤ìŒ Methods ì„¹ì…˜ì„ Nature ë¦¬ë·°ì–´ ê´€ì ì—ì„œ í‰ê°€í•´ì¤˜:
[Methods text]

ë‹¤ìŒ 5ê°€ì§€ ì¸¡ë©´ì—ì„œ ì•½ì ì„ ì§€ì :
1. Reproducibility (ì¬í˜„ì„±)
2. Controls (í†µì œ)
3. Sample size/power (ìƒ˜í”Œ/ê²€ì •ë ¥)
4. Statistical appropriateness (í†µê³„ ì ì ˆì„±)
5. Validation (íƒ€ë‹¹ì„±)

ê° ì•½ì ì— ëŒ€í•´:
- êµ¬ì²´ì  ë¬¸ì œì 
- ë¦¬ë·°ì–´ê°€ ì œê¸°í•  ì§ˆë¬¸
- ê°œì„  ë°©ì•ˆ"
```

---

## 2. Methods ì„¹ì…˜ Bulletproofing ì „ëµ

### 2.1 Reproducibility Checklist

**"ë‹¤ë¥¸ ì—°êµ¬ìê°€ ì •í™•íˆ ì¬í˜„í•  ìˆ˜ ìˆëŠ”ê°€?"**

#### í•„ìˆ˜ í¬í•¨ ìš”ì†Œ

- [ ] **Participants/Subjects**
  - ëª¨ì§‘ ë°©ë²• ë° ì¥ì†Œ
  - Inclusion/exclusion criteria (êµ¬ì²´ì  ê¸°ì¤€)
  - N (ìµœì¢… ë¶„ì„ í¬í•¨ + excluded N + ì´ìœ )
  - Demographics (M age, SD, gender, education ë“±)

- [ ] **Materials**
  - ìê·¹/ë„êµ¬ì˜ êµ¬ì²´ì  ì„¤ëª…
  - ì¶œì²˜ (published source, custom-made)
  - ë²„ì „ (ì†Œí”„íŠ¸ì›¨ì–´, ì²™ë„)
  - ì‹ ë¢°ë„/íƒ€ë‹¹ë„ (Cronbach's Î±, validation reference)

- [ ] **Procedure**
  - Step-by-step protocol (ìˆœì„œëŒ€ë¡œ)
  - ê° ë‹¨ê³„ì˜ íƒ€ì´ë°/ì§€ì† ì‹œê°„
  - ì§€ì‹œë¬¸ (verbatim or paraphrased)
  - ì‹¤í—˜ í™˜ê²½ (ì¡°ëª…, ê±°ë¦¬, í™”ë©´ í¬ê¸° ë“±)

- [ ] **Parameters**
  - ëª¨ë“  ë³€ìˆ˜ì˜ ì •í™•í•œ ê°’
  - ë²”ìœ„, ë‹¨ìœ„
  - Randomization/counterbalancing ë°©ë²•

- [ ] **Software/Equipment**
  - ì´ë¦„, ë²„ì „, manufacturer
  - ì„¤ì •ê°’ (resolution, sampling rate ë“±)

- [ ] **Data processing**
  - Raw data â†’ analyzed data ë³€í™˜ ê³¼ì •
  - Preprocessing steps (filtering, normalization ë“±)
  - Exclusion criteria for trials/participants

#### AI-assisted Reproducibility Audit

```
í”„ë¡¬í”„íŠ¸:
"ë‹¤ìŒ Methods ì„¹ì…˜ì„ ì½ê³ , ë‹¤ë¥¸ ì—°êµ¬ìê°€ ì¬í˜„í•˜ë ¤ í•  ë•Œ
ë§‰í ìˆ˜ ìˆëŠ” ì§€ì  10ê°€ì§€ë¥¼ ì°¾ì•„ì¤˜:
[Methods text]

ê° ì§€ì ì— ëŒ€í•´:
1. ë¬´ì—‡ì´ ë¶ˆëª…í™•í•œê°€?
2. ì–´ë–¤ ì •ë³´ê°€ ì¶”ê°€ë¡œ í•„ìš”í•œê°€?
3. êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–»ê²Œ ê¸°ìˆ í•´ì•¼ í•˜ëŠ”ê°€?
   (Before â†’ After ì˜ˆì‹œ í¬í•¨)"
```

**ì˜ˆì‹œ ì¶œë ¥:**
```
ì§€ì  1: "Participants were recruited online"
ë¬¸ì œ: ì–´ë–¤ í”Œë«í¼? ì–´ë–¤ ê´‘ê³  ë¬¸êµ¬?
í•„ìš” ì •ë³´: ëª¨ì§‘ í”Œë«í¼, ê´‘ê³  ë‚´ìš©, screening ì ˆì°¨
ê°œì„ :
Before: "Participants were recruited online"
After: "Participants were recruited via Prolific (www.prolific.co)
       using the screening criteria: native English speakers,
       18-35 years old, no history of neurological disorders"
```

---

### 2.2 Control Strategy Validation

**"ëŒ€ì•ˆ ì„¤ëª…ì„ ì¶©ë¶„íˆ ë°°ì œí–ˆëŠ”ê°€?"**

#### 4ê°€ì§€ Control ìœ í˜•

1. **Positive controls**
   - ê¸°ëŒ€ë˜ëŠ” íš¨ê³¼ê°€ ì‹¤ì œë¡œ ë‚˜íƒ€ë‚˜ëŠ”ê°€?
   - ì˜ˆ: Known effective manipulationì´ ì˜ˆìƒëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸

2. **Negative controls**
   - íš¨ê³¼ê°€ ì—†ì–´ì•¼ í•  ì¡°ê±´ì—ì„œ ì‹¤ì œë¡œ ì—†ëŠ”ê°€?
   - ì˜ˆ: Sham stimulation ì¡°ê±´ì—ì„œ íš¨ê³¼ ì—†ìŒ

3. **Confound controls**
   - í˜¼ì¬ ë³€ìˆ˜ë¥¼ í†µì œí–ˆëŠ”ê°€?
   - ì˜ˆ: Task difficulty, arousal, expectation í†µì œ

4. **Validation controls**
   - ì¸¡ì •ì´ ì˜ë„í•œ ê²ƒì„ ì¸¡ì •í•˜ëŠ”ê°€?
   - ì˜ˆ: Manipulation check, attention check

#### AI-powered Alternative Explanation Generator

```
í”„ë¡¬í”„íŠ¸:
"ë‚´ ì—°êµ¬ ë””ìì¸:
- Manipulation: [ì„¤ëª…]
- Measurement: [ì„¤ëª…]
- Expected result: [ì„¤ëª…]

ë‹¤ìŒì„ ìƒì„±í•´ì¤˜:
1. Alternative explanations
   (ë‚´ ì¡°ì‘ ì™¸ì— ê²°ê³¼ë¥¼ ì„¤ëª…í•  ìˆ˜ ìˆëŠ” ìš”ì¸ 5ê°€ì§€)
2. ê° alternativeë¥¼ ë°°ì œí•˜ê¸° ìœ„í•œ control ì¡°ê±´
3. ë¦¬ë·°ì–´ê°€ ì§€ì í•  ê°€ëŠ¥ì„±ì´ ë†’ì€ confound 3ê°€ì§€
4. ê° confoundë¥¼ ë‹¤ë£¨ëŠ” ë°©ë²•

ê·¸ë¦¬ê³  í˜„ì¬ ë‚´ Methodsì—ì„œ:
- ì¶©ë¶„íˆ ë‹¤ë¤„ì§„ alternativeëŠ”?
- ì¶”ê°€í•´ì•¼ í•  controlì€?"
```

---

### 2.3 Statistical Power & Sample Size Justification

**"ìƒ˜í”Œ ì‚¬ì´ì¦ˆê°€ ì¶©ë¶„í•œê°€?"**

#### âŒ ì•½í•œ ì •ë‹¹í™” (ê±°ë¶€ ìœ„í—˜)
- "Previous studies used similar N" â†’ ê´€ë¡€ë§Œ ë”°ë¦„
- "We recruited as many as possible" â†’ ê³„íš ì—†ìŒ
- "N=30 is standard" â†’ ê·¼ê±° ì—†ìŒ

#### âœ… ê°•í•œ ì •ë‹¹í™” (í†µê³¼ ê°€ëŠ¥)
- **A priori power analysis**
  - ì˜ˆìƒ íš¨ê³¼ í¬ê¸° (d = 0.5, based on pilot study)
  - Î± = 0.05, power (1-Î²) = 0.80
  - í•„ìš” N ê³„ì‚° (G*Power ì‚¬ìš©)

- **Effect size justification**
  - ì™œ ì´ íš¨ê³¼ í¬ê¸°ë¥¼ ê¸°ëŒ€í•˜ëŠ”ê°€?
  - Pilot data or previous work citation

- **Sensitivity analysis**
  - ë‹¬ì„± ê°€ëŠ¥í•œ minimum detectable effect
  - "With N=60, we can detect d â‰¥ 0.52"

- **Multiple comparisons**
  - Bonferroni/FDR ë³´ì • í›„ì—ë„ ì¶©ë¶„í•œ power

#### AI-assisted Power Analysis Reviewer

```
í”„ë¡¬í”„íŠ¸:
"ë‚´ ì—°êµ¬ ê³„íš:
- Expected effect size: d = [value]
  (ê·¼ê±°: [pilot/previous work])
- Sample size: N = [value]
- Alpha: 0.05
- Planned comparisons: [number]

ë¦¬ë·°ì–´ ê´€ì ì—ì„œ í‰ê°€í•´ì¤˜:
1. Expected effect sizeê°€ í˜„ì‹¤ì ì¸ê°€?
   (ë„ˆë¬´ í¬ê±°ë‚˜ ì‘ì§€ ì•Šì€ê°€?)
2. Multiple comparison ë³´ì •ì„ ê³ ë ¤í•˜ë©´ powerê°€ ì¶©ë¶„í•œê°€?
3. ìƒ˜í”Œ ì‚¬ì´ì¦ˆ ì •ë‹¹í™”ì—ì„œ ë³´ê°•í•  ì ì€?
4. Sensitivity analysis ê²°ê³¼ë¥¼ ì–´ë–»ê²Œ ì œì‹œí•´ì•¼ í•˜ëŠ”ê°€?

ê·¸ë¦¬ê³ :
- ë¦¬ë·°ì–´ê°€ ì œê¸°í•  ê°€ëŠ¥ì„± ë†’ì€ ì§ˆë¬¸ 3ê°€ì§€
- ê° ì§ˆë¬¸ì— ëŒ€í•œ ë°©ì–´ ì „ëµ"
```

---

## 3. Results ì„¹ì…˜ Bulletproofing ì „ëµ

### 3.1 Overclaiming Prevention

**"ì£¼ì¥ì´ ë°ì´í„°ë¥¼ ë„˜ì–´ì„œì§€ ì•ŠëŠ”ê°€?"**

#### í”í•œ Overclaiming íŒ¨í„´

| Claim | Data | Problem | Conservative Alternative |
|-------|------|---------|--------------------------|
| "X **causes** Y" | Correlation between X and Y | Correlation â‰  Causation | "X is **associated with** Y" |
| "X is **necessary** for Y" | Y decreases when X is removed | Sufficiency not tested | "X **contributes to** Y" |
| "Our method **works in general**" | Tested in one specific condition | Generalization unsupported | "Our method works **in [condition]**" |
| "This **proves** theory Z" | Consistent with theory Z | Alternative theories not ruled out | "These findings are **consistent with** theory Z" |

#### AI-powered Claim Checker

```
í”„ë¡¬í”„íŠ¸:
"ë‹¤ìŒ Results ë¬¸ì¥ë“¤ì„ ë¶„ì„í•´ì¤˜:
[Results text with claims]

ê° ë¬¸ì¥ì— ëŒ€í•´:
1. Claim type (causal/correlational/mechanistic/general)
2. Evidence level (direct/indirect/suggestive)
3. Overclaiming risk (1-10)
4. Conservative alternative phrasing

ê·¸ë¦¬ê³ :
- ê°€ì¥ ìœ„í—˜í•œ overclaim 3ê°œ ì§€ì 
- ê°ê°ì„ ë°ì´í„°ì— ë§ê²Œ ìˆ˜ì •í•˜ëŠ” ë°©ë²•"
```

---

### 3.2 Statistical Rigor Verification

**"í†µê³„ ë¶„ì„ì´ ë°©ì–´ ê°€ëŠ¥í•œê°€?"**

#### Critical Checkpoints

- [ ] **Assumption testing**
  - Normality, homogeneity of variance, independence
  - ê°€ì • ìœ„ë°° ì‹œ ëŒ€ì•ˆ ë¶„ì„ (non-parametric, transformation)

- [ ] **Multiple comparisons**
  - ë³´ì • ë°©ë²• ëª…ì‹œ (Bonferroni, FDR, permutation)
  - Family-wise error rate vs false discovery rate

- [ ] **Effect sizes**
  - p-valueë§Œì´ ì•„ë‹Œ effect size + CI ë³´ê³ 
  - Cohen's d, Î·Â², r ë“± (ë¶„ì„ì— ë§ê²Œ)

- [ ] **Outlier handling**
  - ì²˜ë¦¬ ë°©ë²• (removal, winsorization, robust methods)
  - ì˜í–¥ í‰ê°€ (with vs without outliers)

- [ ] **Missing data**
  - ì²˜ë¦¬ ë°©ë²• (listwise deletion, imputation, mixed models)
  - Sensitivity analysis (different methods ë¹„êµ)

- [ ] **Robustness checks**
  - Alternative analysisë¡œ ê²°ê³¼ í™•ì¸
  - ì˜ˆ: Parametric + non-parametric ë‘˜ ë‹¤ ë³´ê³ 

#### AI-assisted Statistical Review

```
í”„ë¡¬í”„íŠ¸:
"ë‚´ Results ì„¹ì…˜:
- Analysis: [í†µê³„ ë¶„ì„ ë°©ë²•]
- Comparisons: [ë¹„êµ íšŸìˆ˜]
- Reported stats: [ì œì‹œí•œ í†µê³„ëŸ‰]

ë¦¬ë·°ì–´ê°€ í†µê³„ì ìœ¼ë¡œ ë¬¸ì œ ì‚¼ì„ ìˆ˜ ìˆëŠ” ë¶€ë¶„:
1. Assumption violations (ì–´ë–¤ ê°€ì •ì´ ë¬¸ì œ?)
2. Multiple comparison issues (ë³´ì •ì´ ì¶©ë¶„í•œê°€?)
3. P-hacking risks (ì˜ì‹¬ë°›ì„ ìˆ˜ ìˆëŠ” ë¶„ì„ ì„ íƒì€?)
4. Missing robustness checks (ì–´ë–¤ ì¶”ê°€ ë¶„ì„ í•„ìš”?)

ê° ë¬¸ì œì— ëŒ€í•´:
- êµ¬ì²´ì  ì§€ì  ë‚´ìš©
- ë°©ì–´ ì „ëµ
- ì¶”ê°€í•  ë¶„ì„/ë³´ê³  ë‚´ìš©"
```

---

### 3.3 Transparent Reporting

**"ëª¨ë“  ê²°ê³¼ë¥¼ íˆ¬ëª…í•˜ê²Œ ë³´ê³ í–ˆëŠ”ê°€?"**

#### Selective reporting ìœ„í—˜ ì‹ í˜¸
- âŒ Hypothesisì— ë§ì§€ ì•ŠëŠ” ê²°ê³¼ ëˆ„ë½
- âŒ ì¼ë¶€ ì¡°ê±´/ì¸¡ì •ì¹˜ë§Œ ë³´ê³ 
- âŒ Failed manipulation checks ì–¸ê¸‰ ì—†ìŒ
- âŒ Exploratory analysisë¥¼ confirmatoryì²˜ëŸ¼ ë³´ê³ 

#### âœ… ì™„ì „ íˆ¬ëª… ë³´ê³  ì „ëµ

**Main Results:**
- ëª¨ë“  planned comparison ë³´ê³  (ìœ ì˜/ë¹„ìœ ì˜ ëª¨ë‘)
- Primary outcome measures ì „ë¶€

**Supplementary:**
- ëª¨ë“  ì¸¡ì • ë³€ìˆ˜ ê²°ê³¼ (ë©”ì¸ì— ì•ˆ ë“¤ì–´ê°„ ê²ƒë„)
- Manipulation checks
- Assumption testing ê²°ê³¼
- Robustness checks
- Excluded data + ì´ìœ 
- Exploratory analyses (ëª…í™•íˆ í‘œì‹œ)

**Open Science:**
- Pre-registration (ìˆë‹¤ë©´ ë§í¬)
- Data/code availability statement
- Materials availability

#### AI-powered Transparency Checker

```
í”„ë¡¬í”„íŠ¸:
"ë‚´ ì—°êµ¬ ê³„íš:
- Hypotheses: [list]
- Planned comparisons: [list]
- Measured variables: [list]

í˜„ì¬ Results ì„¹ì…˜:
[Results text]

íˆ¬ëª…ì„± í‰ê°€:
1. Planned ëŒ€ë¹„ ë³´ê³ ëœ ë¹„ìœ¨ (%)
2. ëˆ„ë½ëœ ê²°ê³¼ê°€ ìˆëŠ”ê°€? ì–´ë–¤ ê²ƒ?
3. Exploratory vs Confirmatory êµ¬ë¶„ì´ ëª…í™•í•œê°€?
4. Selective reporting ì˜ì‹¬ë°›ì„ ìˆ˜ ìˆëŠ” ë¶€ë¶„ì€?

ê°œì„  ë°©ì•ˆ:
- Mainì— ì¶”ê°€í•  ê²°ê³¼
- Supplementaryë¡œ ì˜®ê¸¸ ê²°ê³¼
- íˆ¬ëª…ì„± ê°•í™”ë¥¼ ìœ„í•œ ë¬¸êµ¬ ì œì•ˆ"
```

---

## 4. Preemptive Reviewer Response ì „ëµ

### 4.1 "Reviewerê°€ ë¬¼ì–´ë³¼ ì§ˆë¬¸" ì˜ˆì¸¡

#### AIë¥¼ í™œìš©í•œ Anticipated Questions ìƒì„±

```
í”„ë¡¬í”„íŠ¸:
"ë‚´ Methods/Results:
[ì „ì²´ í…ìŠ¤íŠ¸]

Nature/Science ë¦¬ë·°ì–´ê°€ ì œê¸°í•  ê°€ëŠ¥ì„±ì´ ë†’ì€ ì§ˆë¬¸ 10ê°€ì§€ë¥¼ ìƒì„±í•´ì¤˜.
ê° ì§ˆë¬¸ì— ëŒ€í•´:
1. ì§ˆë¬¸ ìœ í˜• (reproducibility/controls/statistics/interpretation)
2. ì‹¬ê°ë„ (critical/major/minor)
3. í˜„ì¬ Methods/Resultsì—ì„œ ë‹µë³€ì´ ìˆëŠ”ê°€?
4. ì—†ë‹¤ë©´, Methods/Resultsì— ì¶”ê°€í•  ë‚´ìš©
5. Rebuttal letterì—ì„œ ë‹µë³€í•  ë‚´ìš©

ìš°ì„ ìˆœìœ„ ìˆœìœ¼ë¡œ ì •ë ¬í•´ì¤˜."
```

#### Preemptive Defense ì‚½ì…
- **Critical questions** â†’ Methods/Resultsì— ì§ì ‘ ë‹µë³€ ì¶”ê°€
- **Major questions** â†’ Supplementaryì—ì„œ ë‹¤ë£¸
- **Minor questions** â†’ Rebuttalì—ì„œë§Œ ëŒ€ì‘

---

### 4.2 Methods/Results Cross-Validation

**"Methodsì—ì„œ ì•½ì†í•œ ê²ƒì„ Resultsì—ì„œ ì „ë¶€ ë‹¤ë¤˜ëŠ”ê°€?"**

#### í”í•œ ë¶ˆì¼ì¹˜
- âŒ Methodsì—ì„œ ì–¸ê¸‰í•œ ë¶„ì„ì´ Resultsì— ì—†ìŒ
- âŒ Resultsì˜ ë¶„ì„ì´ Methodsì— ì„¤ëª… ì•ˆ ë¨
- âŒ Control ì¡°ê±´ì„ Methodsì—ì„œ ì–¸ê¸‰í–ˆì§€ë§Œ Resultsì— ê²°ê³¼ ì—†ìŒ
- âŒ Exclusion criteria ì–¸ê¸‰í–ˆì§€ë§Œ excluded N ë³´ê³  ì•ˆ ë¨

#### AI-powered Consistency Checker

```
í”„ë¡¬í”„íŠ¸:
"ë‚´ Methods ì„¹ì…˜:
[Methods text]

ë‚´ Results ì„¹ì…˜:
[Results text]

ì¼ê´€ì„± ì²´í¬:
1. Methodsì— ìˆì§€ë§Œ Resultsì— ì—†ëŠ” ë¶„ì„/ì¸¡ì •/ì¡°ê±´
2. Resultsì— ìˆì§€ë§Œ Methodsì— ì„¤ëª… ì—†ëŠ” ë¶„ì„
3. ìš©ì–´ ë¶ˆì¼ì¹˜ (ê°™ì€ ê²ƒì„ ë‹¤ë¥´ê²Œ ì§€ì¹­)
4. ìˆ«ì ë¶ˆì¼ì¹˜ (N, df ë“±)

ê° ë¶ˆì¼ì¹˜ì— ëŒ€í•´:
- ë¬¸ì œ ìœ í˜•
- ìˆ˜ì • ë°©ë²• (Methods ì¶”ê°€ vs Results ì¶”ê°€ vs ì‚­ì œ)"
```

---

## 5. Effect Size & Significance í†µí•© ë³´ê³ 

### 5.1 P-valueë§Œìœ¼ë¡œëŠ” ë¶€ì¡±

#### âŒ ì•½í•œ ë³´ê³ 
"p < 0.05ì´ë¯€ë¡œ ìœ ì˜í•˜ë‹¤"

#### âœ… ê°•í•œ ë³´ê³  (ê¶Œì¥ í…œí”Œë¦¿)
```
"Group A (M = 85.3, SD = 12.1) significantly outperformed
Group B (M = 72.4, SD = 10.8), t(98) = 5.43, p < .001,
Cohen's d = 1.12, 95% CI [0.71, 1.53]"
```

**í¬í•¨ ìš”ì†Œ:**
- Descriptive stats (M, SD)
- Inferential stats (t, df, p)
- Effect size (Cohen's d)
- Confidence interval (95% CI)

---

### 5.2 Practical Significance vs Statistical Significance

**"í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ë§Œ ì‹¤ì§ˆì  ì˜ë¯¸ëŠ”?"**

#### AIë¥¼ í™œìš©í•œ Practical Significance í‰ê°€

```
í”„ë¡¬í”„íŠ¸:
"ë‚´ ì£¼ìš” ë°œê²¬:
- Effect size: Cohen's d = [value]
- Comparison: [experimental vs control/baseline/previous work]

ë‹¤ìŒì„ í‰ê°€í•´ì¤˜:
1. ì´ effect sizeê°€ í•´ë‹¹ ë¶„ì•¼ì—ì„œ ì–´ëŠ ì •ë„ í¬ê¸°ì¸ê°€?
   (small/medium/large ì ˆëŒ€ ê¸°ì¤€ ë§ê³ , ë¶„ì•¼ ë§¥ë½ì—ì„œ)
2. Practical significanceëŠ”?
   - ì‹¤ì œ ì‘ìš© ê´€ì ì—ì„œ ì˜ë¯¸ ìˆëŠ” ì°¨ì´ì¸ê°€?
   - Minimum clinically/practically important differenceì™€ ë¹„êµí•˜ë©´?
3. Effect sizeë¥¼ ë³´ê³ í•  ë•Œ ì¶”ê°€í•  ë§¥ë½ ì •ë³´
   - ë¹„êµ ëŒ€ìƒ (ì´ì „ ì—°êµ¬, ì´ë¡ ì  ì˜ˆì¸¡, ì‹¤ìš©ì  ê¸°ì¤€)
   - ì‹ ë¢°êµ¬ê°„ í•´ì„

ë¦¬ë·°ì–´ê°€ 'í†µê³„ì ìœ¼ë¡œë§Œ ìœ ì˜í•˜ê³  ì‹¤ì§ˆì  ì˜ë¯¸ ì—†ë‹¤'ê³ 
ì§€ì í•  ìœ„í—˜ì´ ìˆëŠ”ê°€?"
```

---

## 6. ë™ë£Œ Methods/Results Review í”„ë¡œí† ì½œ

### 6.1 Structured Peer Review Template

**ê° í•™ìƒì´ 2ëª…ì˜ ë™ë£Œ Methods/Resultsë¥¼ í‰ê°€:**

```
=== METHODS í‰ê°€ ===

1. Reproducibility (1-5ì ): ___
   - ë‚´ê°€ ì´ ì—°êµ¬ë¥¼ ì¬í˜„í•˜ë ¤ í•  ë•Œ ë§‰í ë¶€ë¶„:
   - ì¶”ê°€ë¡œ í•„ìš”í•œ ì •ë³´:

2. Controls (1-5ì ): ___
   - Alternative explanationsì´ ì¶©ë¶„íˆ ë°°ì œëëŠ”ê°€?
   - ë‚´ê°€ ë¦¬ë·°ì–´ë¼ë©´ ì¶”ê°€í•  control:

3. Statistical Justification (1-5ì ): ___
   - Sample size ì •ë‹¹í™”ê°€ ì„¤ë“ë ¥ ìˆëŠ”ê°€?
   - ë¶„ì„ ë°©ë²•ì´ ë°ì´í„° êµ¬ì¡°ì— ì í•©í•œê°€?

=== RESULTS í‰ê°€ ===

4. Claim-Evidence Match (1-5ì ): ___
   - Overclaiming ìœ„í—˜ì´ ìˆëŠ” ë¬¸ì¥ (ìˆë‹¤ë©´ ì§€ì ):
   - ë³´ìˆ˜ì ìœ¼ë¡œ ìˆ˜ì •í•  ë°©ë²•:

5. Statistical Rigor (1-5ì ): ___
   - ë¹ ì§„ í†µê³„ëŸ‰/ê²€ì •:
   - Multiple comparison ì²˜ë¦¬ ì ì ˆí•œê°€?

6. Transparency (1-5ì ): ___
   - ì„ íƒì  ë³´ê³  ì˜ì‹¬ ë¶€ë¶„:
   - ì¶”ê°€ë¡œ ë³´ê³ í•´ì•¼ í•  ê²°ê³¼:

=== ì¢…í•© ===
- ê°€ì¥ í° ì•½ì  1ê°€ì§€:
- ê°œì„  ìš°ì„ ìˆœìœ„ top 3:
- Nature/Science ì œì¶œ ì¤€ë¹„ë„ (1-10):
```

---

## Workshop ì‹¤ìŠµ (70-75ë¶„)

### Phase 1: Bulletproofing Audit (25ë¶„)

**Activity 1 (12ë¶„): Methods reproducibility check**
- AIë¡œ ì¬í˜„ì„± ì·¨ì•½ì  10ê°€ì§€ ë„ì¶œ
- ê° ì·¨ì•½ì  ê°œì„  ë°©ë²• ë…¼ì˜

**Activity 2 (13ë¶„): Results claim checker**
- Overclaiming ìœ„í—˜ ë¬¸ì¥ ì‹ë³„
- Effect size + practical significance í‰ê°€

### Phase 2: Statistical Rigor (20ë¶„)

**Activity 3 (12ë¶„): Power analysis review**
- AIë¡œ sample size ì •ë‹¹í™” ê°•í™”
- Multiple comparison ë³´ì • ì²´í¬

**Activity 4 (8ë¶„): Transparency audit**
- Selective reporting ìœ„í—˜ í‰ê°€
- ì¶”ê°€ ë³´ê³  í•„ìš” í•­ëª© ë¦¬ìŠ¤íŠ¸

### Phase 3: Peer Review (20ë¶„)

**Activity 5: Structured peer review**
- 2ëª… ë™ë£Œ í‰ê°€ (template ì‚¬ìš©)
- ë¦¬ë·°ì–´ ì§ˆë¬¸ ì˜ˆì¸¡ ë° ë°©ì–´ ì „ëµ ë…¼ì˜

### Phase 4: ìµœì¢… ê°œì„  + ê³µìœ  (10ë¶„)

**Activity 6: AIë¡œ í”¼ë“œë°± í†µí•©**
- ë°›ì€ í”¼ë“œë°± ë°˜ì˜í•œ ê°œì„ ì•ˆ ìƒì„± (7ë¶„)
- ê°€ì¥ íš¨ê³¼ì ì´ì—ˆë˜ bulletproofing ì „ëµ ê³µìœ  (3ë¶„)

**ì´ Workshop ì‹œê°„: 75ë¶„ (ê°•ì˜ 15-20ë¶„ í¬í•¨í•˜ë©´ 90-95ë¶„)**

---

## ê³¼ì œ (ë‹¤ìŒ ì£¼ê¹Œì§€)

### "My Methods/Results - Bulletproofed"

**ì œì¶œë¬¼:**

1. **Methods ì„¹ì…˜ ì™„ì„± (800-1000 words)**
   - Reproducibility checklist ì „ë¶€ ì¶©ì¡±
   - Control strategy ì •ë‹¹í™”
   - Statistical power/sample size ê·¼ê±°
   - 6ê°€ì§€ í•„ìˆ˜ ìš”ì†Œ ëª¨ë‘ í¬í•¨

2. **Results ì„¹ì…˜ ì™„ì„± (600-800 words)**
   - ëª¨ë“  ì£¼ìš” ê²°ê³¼ (effect size + CI + p)
   - Figure/Table ìµœì†Œ 1ê°œ
   - Overclaiming ì—†ëŠ” conservative claims
   - Transparent reporting

3. **Bulletproofing Documentation (800 words)**
   - **AIë¥¼ í™œìš©í•œ self-critique ê²°ê³¼**
     - Reproducibility audit (10 vulnerable points)
     - Alternative explanation check
     - Statistical review
   - **ì˜ˆìƒ ë¦¬ë·°ì–´ ì§ˆë¬¸ 5ê°œ + ë°©ì–´ ì „ëµ**
     - Critical questions (ì–´ë–»ê²Œ Methods/Resultsì— ë‹µë³€?)
     - Major questions (Supplementary plan)
   - **Transparency checklist ì¶©ì¡± ì¦ë¹™**
     - ëª¨ë“  planned comparison ë³´ê³  í™•ì¸
     - Exploratory vs confirmatory êµ¬ë¶„

4. **AI í™œìš© ê³¼ì • (500 words)**
   - ì‚¬ìš©í•œ í”„ë¡¬í”„íŠ¸ ë ˆì‹œí”¼ **5ê°œ ì´ìƒ**
   - ê° ë ˆì‹œí”¼ì˜ íš¨ê³¼ ë° í•œê³„
   - AIì˜ í•œê³„ ë° ì¸ê°„ íŒë‹¨ì´ í•„ìš”í–ˆë˜ ì§€ì 

5. **Peer Review ë°˜ì˜ (300 words)**
   - ë°›ì€ í”¼ë“œë°± ìš”ì•½ (6ê°€ì§€ í‰ê°€ í•­ëª©ë³„)
   - ê° í”¼ë“œë°±ì„ ì–´ë–»ê²Œ ë°˜ì˜í–ˆëŠ”ì§€

### í‰ê°€ ê¸°ì¤€

- **Reproducibility & Rigor (40%)**
  - ì¬í˜„ì„± (6ê°€ì§€ ìš”ì†Œ ì¶©ì¡±)
  - Control (alternative explanation ë°°ì œ)
  - í†µê³„ ì •ë‹¹í™” (power analysis, appropriate tests)

- **Transparent Reporting (25%)**
  - ì™„ì „í•œ ê²°ê³¼ ë³´ê³  (ëª¨ë“  planned comparison)
  - Overclaiming ë°©ì§€ (claim-evidence match)
  - Open science practices

- **Reviewer-Ready (20%)**
  - ì˜ˆìƒ ì§ˆë¬¸ ëŒ€ì‘ (preemptive defense)
  - Methods/Results ì¼ê´€ì„±
  - Effect size + practical significance

- **AI í™œìš© & Peer Review (15%)**
  - íš¨ê³¼ì  í”„ë¡¬í”„íŠ¸ (5ê°œ ì´ìƒ)
  - ë¹„íŒì  ê²€í†  ë° ê°œì„ 
  - ë™ë£Œ í”¼ë“œë°± ë°˜ì˜

---

## í•µì‹¬ ë©”ì‹œì§€

### Bulletproof Methods/Resultsì˜ ì¡°ê±´
```
Reproducibility (6ê°€ì§€ ìš”ì†Œ)
     +
Control (alternative explanation ë°°ì œ)
     +
Statistical Rigor (power, assumptions, effect size)
     +
Transparent Reporting (ëª¨ë“  ê²°ê³¼, no overclaiming)
     +
Preemptive Defense (ì˜ˆìƒ ì§ˆë¬¸ì— ë¯¸ë¦¬ ë‹µë³€)
     =
Nature/Science ë¦¬ë·°ì–´ê°€ ê³µê²©í•  í‹ˆ ì—†ëŠ” Methods/Results
```

### CoTì˜ ì—­í• 
> "ìœ¤ê²½ìƒ ê°•ì˜ì—ì„œ CoT **ê¸°ë²•**ì„ ë°°ì› ë‹¤ë©´,
> ë³¸ ê°•ì˜ì—ì„œëŠ” CoTë¥¼ 'ë¦¬ë·°ì–´ ê³µê²© ë°©ì–´'ë¼ëŠ” **ëª©í‘œ**ì— ì „ëµì ìœ¼ë¡œ í™œìš©."

---

## í† ë¡  ì£¼ì œ

1. **Reproducibility**: ìì‹ ì˜ Methodsì—ì„œ ê°€ì¥ ì·¨ì•½í•œ ë¶€ë¶„ì€? ì–´ë–»ê²Œ ë³´ê°•í•  ê²ƒì¸ê°€?

2. **Overclaiming**: Resultsì—ì„œ ë°ì´í„°ë¥¼ ë„˜ì–´ì„œëŠ” ì£¼ì¥ì„ í•˜ê³  ìˆì§€ ì•Šì€ê°€?

3. **Statistical rigor**: Multiple comparisonì„ ê³ ë ¤í•˜ë©´ ê²°ê³¼ê°€ ì—¬ì „íˆ ìœ ì˜í•œê°€?

4. **Reviewer questions**: ë¦¬ë·°ì–´ê°€ ê°€ì¥ ê³µê²©í•  ê°€ëŠ¥ì„±ì´ ë†’ì€ ë¶€ë¶„ì€?

---

## ë‹¤ìŒ ì£¼ ì¤€ë¹„ì‚¬í•­

- **Discussion ì„¹ì…˜ ì´ˆì•ˆ ì‘ì„±**
  - ê²°ê³¼ì˜ broader implications
  - í•œê³„ì  ë° future directions
  - Conclusion

- **ì „ì²´ ë…¼ë¬¸ í†µí•©**
  - Abstract â†’ Introduction â†’ Methods â†’ Results â†’ Discussion
  - ì¼ê´€ì„± ì²´í¬
  - ìµœì¢… ê²€í† 

---

## ì°¸ê³  ìë£Œ

### ì¶”ì²œ ì½ê¸°
- Nature/Science Methods ì„¹ì…˜ 10í¸
  - ì–´ë–»ê²Œ reproducibilityë¥¼ ë‹¬ì„±í•˜ëŠ”ì§€
  - Control strategy íŒ¨í„´ íŒŒì•…

- APA Publication Manual (7th ed.)
  - Statistical reporting guidelines
  - Effect size reporting standards

### í”„ë¡¬í”„íŠ¸ ë ˆì‹œí”¼ ë¼ì´ë¸ŒëŸ¬ë¦¬
- ê³µìœ  ê²Œì‹œíŒì—ì„œ ë™ë£Œë“¤ì˜ íš¨ê³¼ì  bulletproofing í”„ë¡¬í”„íŠ¸ ì°¸ê³ 
- Reproducibility audit, statistical review í”„ë¡¬í”„íŠ¸ ì ê·¹ ê³µìœ 

### AI ë„êµ¬ ì¶”ì²œ
- **ChatGPT**: Reproducibility audit, alternative explanation generation
- **Claude**: Statistical review, reviewer question prediction
- **Perplexity**: í†µê³„ ë°©ë²• best practices ê²€ìƒ‰
- **G*Power**: Power analysis (AIê°€ ì•„ë‹Œ ì „ìš© ì†Œí”„íŠ¸ì›¨ì–´)
